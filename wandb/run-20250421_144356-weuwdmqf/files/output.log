[34m[1mwandb[0m: [33mWARNING[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -50      |
|    success_rate    | 0        |
| time/              |          |
|    fps             | 57       |
|    iterations      | 1        |
|    time_elapsed    | 35       |
|    total_timesteps | 2048     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -50          |
|    success_rate         | 0            |
| time/                   |              |
|    fps                  | 56           |
|    iterations           | 2            |
|    time_elapsed         | 73           |
|    total_timesteps      | 4096         |
| train/                  |              |
|    approx_kl            | 0.0040933522 |
|    clip_fraction        | 0.0458       |
|    clip_range           | 0.2          |
|    entropy_loss         | -5.68        |
|    explained_variance   | 0.00522      |
|    learning_rate        | 0.0003       |
|    loss                 | 7.86         |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.00221     |
|    std                  | 1            |
|    value_loss           | 47.4         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -50          |
|    success_rate         | 0            |
| time/                   |              |
|    fps                  | 55           |
|    iterations           | 3            |
|    time_elapsed         | 111          |
|    total_timesteps      | 6144         |
| train/                  |              |
|    approx_kl            | 0.0034617013 |
|    clip_fraction        | 0.0041       |
|    clip_range           | 0.2          |
|    entropy_loss         | -5.68        |
|    explained_variance   | 0.00595      |
|    learning_rate        | 0.0003       |
|    loss                 | 13.9         |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.00126     |
|    std                  | 1            |
|    value_loss           | 66.9         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50          |
|    ep_rew_mean          | -50         |
|    success_rate         | 0           |
| time/                   |             |
|    fps                  | 54          |
|    iterations           | 4           |
|    time_elapsed         | 150         |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.004299227 |
|    clip_fraction        | 0.0108      |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.68       |
|    explained_variance   | 0.00224     |
|    learning_rate        | 0.0003      |
|    loss                 | 12.3        |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00208    |
|    std                  | 1           |
|    value_loss           | 55          |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50          |
|    ep_rew_mean          | -50         |
|    success_rate         | 0           |
| time/                   |             |
|    fps                  | 54          |
|    iterations           | 5           |
|    time_elapsed         | 188         |
|    total_timesteps      | 10240       |
| train/                  |             |
|    approx_kl            | 0.004892654 |
|    clip_fraction        | 0.0111      |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.68       |
|    explained_variance   | 0.0012      |
|    learning_rate        | 0.0003      |
|    loss                 | 7.95        |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.00212    |
|    std                  | 0.999       |
|    value_loss           | 44.7        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50          |
|    ep_rew_mean          | -50         |
|    success_rate         | 0           |
| time/                   |             |
|    fps                  | 54          |
|    iterations           | 6           |
|    time_elapsed         | 226         |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.004782331 |
|    clip_fraction        | 0.0271      |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.67       |
|    explained_variance   | 0.000544    |
|    learning_rate        | 0.0003      |
|    loss                 | 6.46        |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.00301    |
|    std                  | 0.999       |
|    value_loss           | 35.4        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -50          |
|    success_rate         | 0            |
| time/                   |              |
|    fps                  | 54           |
|    iterations           | 7            |
|    time_elapsed         | 264          |
|    total_timesteps      | 14336        |
| train/                  |              |
|    approx_kl            | 0.0053518857 |
|    clip_fraction        | 0.0328       |
|    clip_range           | 0.2          |
|    entropy_loss         | -5.67        |
|    explained_variance   | 0.000534     |
|    learning_rate        | 0.0003       |
|    loss                 | 4.08         |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.00391     |
|    std                  | 0.996        |
|    value_loss           | 27.4         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -50          |
|    success_rate         | 0            |
| time/                   |              |
|    fps                  | 54           |
|    iterations           | 8            |
|    time_elapsed         | 302          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0057219304 |
|    clip_fraction        | 0.0372       |
|    clip_range           | 0.2          |
|    entropy_loss         | -5.66        |
|    explained_variance   | 0.000398     |
|    learning_rate        | 0.0003       |
|    loss                 | 2.96         |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.00367     |
|    std                  | 1            |
|    value_loss           | 20.5         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -50          |
|    success_rate         | 0            |
| time/                   |              |
|    fps                  | 54           |
|    iterations           | 9            |
|    time_elapsed         | 339          |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 0.0074401824 |
|    clip_fraction        | 0.0391       |
|    clip_range           | 0.2          |
|    entropy_loss         | -5.66        |
|    explained_variance   | 0.000201     |
|    learning_rate        | 0.0003       |
|    loss                 | 2.27         |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00248     |
|    std                  | 0.988        |
|    value_loss           | 15           |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50          |
|    ep_rew_mean          | -50         |
|    success_rate         | 0           |
| time/                   |             |
|    fps                  | 54          |
|    iterations           | 10          |
|    time_elapsed         | 377         |
|    total_timesteps      | 20480       |
| train/                  |             |
|    approx_kl            | 0.005302821 |
|    clip_fraction        | 0.0338      |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.63       |
|    explained_variance   | 0.000145    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.72        |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.00143    |
|    std                  | 0.992       |
|    value_loss           | 11.3        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50          |
|    ep_rew_mean          | -50         |
|    success_rate         | 0           |
| time/                   |             |
|    fps                  | 54          |
|    iterations           | 11          |
|    time_elapsed         | 414         |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.008216553 |
|    clip_fraction        | 0.0204      |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.62       |
|    explained_variance   | 0.000199    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.5         |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.00287    |
|    std                  | 0.976       |
|    value_loss           | 8.16        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -50          |
|    success_rate         | 0            |
| time/                   |              |
|    fps                  | 54           |
|    iterations           | 12           |
|    time_elapsed         | 451          |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 0.0067749396 |
|    clip_fraction        | 0.0333       |
|    clip_range           | 0.2          |
|    entropy_loss         | -5.56        |
|    explained_variance   | 0.000251     |
|    learning_rate        | 0.0003       |
|    loss                 | 1.13         |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00284     |
|    std                  | 0.963        |
|    value_loss           | 5.79         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -50          |
|    success_rate         | 0            |
| time/                   |              |
|    fps                  | 54           |
|    iterations           | 13           |
|    time_elapsed         | 488          |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 0.0053751385 |
|    clip_fraction        | 0.0207       |
|    clip_range           | 0.2          |
|    entropy_loss         | -5.51        |
|    explained_variance   | 0.000224     |
|    learning_rate        | 0.0003       |
|    loss                 | 0.675        |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00294     |
|    std                  | 0.951        |
|    value_loss           | 4.16         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50          |
|    ep_rew_mean          | -50         |
|    success_rate         | 0           |
| time/                   |             |
|    fps                  | 54          |
|    iterations           | 14          |
|    time_elapsed         | 525         |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.006191276 |
|    clip_fraction        | 0.0259      |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.46       |
|    explained_variance   | 0.000284    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.655       |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.00381    |
|    std                  | 0.939       |
|    value_loss           | 3.1         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -50          |
|    success_rate         | 0            |
| time/                   |              |
|    fps                  | 54           |
|    iterations           | 15           |
|    time_elapsed         | 562          |
|    total_timesteps      | 30720        |
| train/                  |              |
|    approx_kl            | 0.0044432906 |
|    clip_fraction        | 0.0203       |
|    clip_range           | 0.2          |
|    entropy_loss         | -5.42        |
|    explained_variance   | 0.000324     |
|    learning_rate        | 0.0003       |
|    loss                 | 0.542        |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00228     |
|    std                  | 0.938        |
|    value_loss           | 2.28         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -50          |
|    success_rate         | 0            |
| time/                   |              |
|    fps                  | 54           |
|    iterations           | 16           |
|    time_elapsed         | 599          |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0065966276 |
|    clip_fraction        | 0.0422       |
|    clip_range           | 0.2          |
|    entropy_loss         | -5.42        |
|    explained_variance   | 0.000337     |
|    learning_rate        | 0.0003       |
|    loss                 | 0.403        |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00481     |
|    std                  | 0.941        |
|    value_loss           | 1.6          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50          |
|    ep_rew_mean          | -50         |
|    success_rate         | 0           |
| time/                   |             |
|    fps                  | 54          |
|    iterations           | 17          |
|    time_elapsed         | 638         |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.006235918 |
|    clip_fraction        | 0.0294      |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.4        |
|    explained_variance   | 0.000695    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.305       |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.00431    |
|    std                  | 0.922       |
|    value_loss           | 1.18        |
-----------------------------------------
Traceback (most recent call last):
  File "C:\Users\defre\OneDrive\Desktop\ELE392Project\Reinforcement-Learning-Project\testing.py", line 40, in <module>
    model.learn(total_timesteps=100_000)
  File "C:\Users\defre\OneDrive\Desktop\ELE392Project\Reinforcement-Learning-Project\venv\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 311, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\defre\OneDrive\Desktop\ELE392Project\Reinforcement-Learning-Project\venv\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 324, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\defre\OneDrive\Desktop\ELE392Project\Reinforcement-Learning-Project\venv\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 218, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\defre\OneDrive\Desktop\ELE392Project\Reinforcement-Learning-Project\venv\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 222, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\defre\OneDrive\Desktop\ELE392Project\Reinforcement-Learning-Project\venv\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 59, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\defre\OneDrive\Desktop\ELE392Project\Reinforcement-Learning-Project\venv\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\defre\OneDrive\Desktop\ELE392Project\Reinforcement-Learning-Project\venv\Lib\site-packages\gymnasium\wrappers\common.py", line 125, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\defre\OneDrive\Desktop\ELE392Project\Reinforcement-Learning-Project\venv\Lib\site-packages\gymnasium\wrappers\common.py", line 393, in step
    return super().step(action)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\defre\OneDrive\Desktop\ELE392Project\Reinforcement-Learning-Project\venv\Lib\site-packages\gymnasium\core.py", line 327, in step
    return self.env.step(action)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\defre\OneDrive\Desktop\ELE392Project\Reinforcement-Learning-Project\venv\Lib\site-packages\gymnasium\wrappers\common.py", line 285, in step
    return self.env.step(action)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\defre\OneDrive\Desktop\ELE392Project\Reinforcement-Learning-Project\venv\Lib\site-packages\gymnasium_robotics\envs\robot_env.py", line 140, in step
    self.render()
  File "C:\Users\defre\OneDrive\Desktop\ELE392Project\Reinforcement-Learning-Project\venv\Lib\site-packages\gymnasium_robotics\envs\robot_env.py", line 317, in render
    return self.mujoco_renderer.render(self.render_mode)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\defre\OneDrive\Desktop\ELE392Project\Reinforcement-Learning-Project\venv\Lib\site-packages\gymnasium\envs\mujoco\mujoco_rendering.py", line 736, in render
    return viewer.render()
           ^^^^^^^^^^^^^^^
  File "C:\Users\defre\OneDrive\Desktop\ELE392Project\Reinforcement-Learning-Project\venv\Lib\site-packages\gymnasium\envs\mujoco\mujoco_rendering.py", line 458, in render
    update()
  File "C:\Users\defre\OneDrive\Desktop\ELE392Project\Reinforcement-Learning-Project\venv\Lib\site-packages\gymnasium\envs\mujoco\mujoco_rendering.py", line 439, in update
    glfw.swap_buffers(self.window)
  File "C:\Users\defre\OneDrive\Desktop\ELE392Project\Reinforcement-Learning-Project\venv\Lib\site-packages\glfw\__init__.py", line 2380, in swap_buffers
    _glfw.glfwSwapBuffers(window)
  File "C:\Users\defre\OneDrive\Desktop\ELE392Project\Reinforcement-Learning-Project\venv\Lib\site-packages\glfw\__init__.py", line 687, in errcheck
    def errcheck(result, *args):

KeyboardInterrupt
